{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "book_to_audio_book.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB7RfbptUebr"
      },
      "source": [
        "!git clone https://github.com/TensorSpeech/TensorFlowTTS.git\n",
        "!cd TensorFlowTTS\n",
        "!pip install -q /content/TensorFlowTTS/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLCGwt3bWybA"
      },
      "source": [
        "!pip install -q pytesseract pdf2image tf-nightly\n",
        "!pip install -q git+https://github.com/repodiac/german_transliterate.git#egg=german_transliterate\n",
        "!apt-get install -y poppler-utils tesseract-ocr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTZ1cm3nZ0IX"
      },
      "source": [
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import yaml\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append('/content/TensorFlowTTS')\n",
        "from tensorflow_tts.inference import AutoProcessor\n",
        "from tensorflow_tts.inference import TFAutoModel\n",
        "import IPython.display as ipd\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import gc\n",
        "import logging\n",
        "from google.colab import files\n",
        "logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%H:%M:%S', level=logging.DEBUG)\n",
        "print(tf.__version__) # check if >= 2.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhPOTfgRZVwV"
      },
      "source": [
        "# Path of the pdf\n",
        "PDF_file = \"input_file.pdf\"\n",
        "\n",
        "  \n",
        "# Store all the pages of the PDF in a variable\n",
        "pages = convert_from_path(PDF_file, 500)\n",
        "  \n",
        "# Counter to store images of each page of PDF to image\n",
        "image_counter = 1\n",
        "  \n",
        "# Iterate through all the pages stored above\n",
        "for page in pages:\n",
        "  \n",
        "    filename = \"page_\"+str(image_counter)+\".jpg\"\n",
        "      \n",
        "    # Save the image of the page in system\n",
        "    page.save(filename, 'JPEG')\n",
        "  \n",
        "    # Increment the counter to update filename\n",
        "    image_counter = image_counter + 1\n",
        "  \n",
        "# Variable to get count of total number of pages\n",
        "filelimit = image_counter-1\n",
        "  \n",
        "# Creating a text file to write the output\n",
        "outfile = \"out_text.txt\"\n",
        "  \n",
        "# Open the file in append mode so that \n",
        "# All contents of all images are added to the same file\n",
        "f = open(outfile, \"a\")\n",
        "  \n",
        "# Iterate from 1 to total number of pages\n",
        "for i in range(1, filelimit + 1):\n",
        "  \n",
        "    filename = \"page_\"+str(i)+\".jpg\"\n",
        "          \n",
        "    # Recognize the text as string in image using pytesserct\n",
        "    text = str(((pytesseract.image_to_string(Image.open(filename)))))\n",
        "  \n",
        "    text = text.replace('-\\n', '')    \n",
        "  \n",
        "    # Finally, write the processed text to the file.\n",
        "    f.write(text)\n",
        "  \n",
        "# Close the file after writing all the text.\n",
        "f.close()\n",
        "\n",
        "text = open(outfile, \"r\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HBbsKHLyULN"
      },
      "source": [
        "def text_to_speech(book_name, text, save_every=50):\n",
        "\n",
        "  # initialize fastspeech2 model.\n",
        "  fastspeech2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-fastspeech2-ljspeech-en\")\n",
        "\n",
        "\n",
        "  # initialize mb_melgan model\n",
        "  mb_melgan = TFAutoModel.from_pretrained(\"tensorspeech/tts-mb_melgan-ljspeech-en\")\n",
        "\n",
        "\n",
        "  # inference\n",
        "  processor = AutoProcessor.from_pretrained(\"tensorspeech/tts-fastspeech2-ljspeech-en\")\n",
        "\n",
        "  n = 200\n",
        "  chunks = [text[i:i + n] for i in range(0, len(text), n)]\n",
        "  audios = []\n",
        "  count = 0\n",
        "  for chunk in chunks:\n",
        "    input_ids = processor.text_to_sequence(chunk)\n",
        "    # fastspeech inference\n",
        "\n",
        "    mel_before, mel_after, duration_outputs, _, _ = fastspeech2.inference(\n",
        "        input_ids=tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
        "        speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n",
        "        speed_ratios=tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "        f0_ratios =tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "        energy_ratios =tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "    )\n",
        "\n",
        "    # melgan inference\n",
        "    #audio_before = mb_melgan.inference(mel_before)[0, :, 0]\n",
        "    audio_after = mb_melgan.inference(mel_after)[0, :, 0]\n",
        "\n",
        "    file_name = f'./{book_name}_cd_{count}.wav'\n",
        "    print(f'saving audio to {file_name}')\n",
        "    sf.write(file_name, audio_after, 22050, \"PCM_16\")\n",
        "    count += 1\n",
        "\n",
        "book = 'benjamin_franklin_the_way_to_wealth'\n",
        "text_to_speech(book, text, save_every=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61W0WqxOQSZG"
      },
      "source": [
        "import glob\n",
        "import wave\n",
        "\n",
        "infiles = glob.glob('*.wav')\n",
        "outfile = book + \".wav\"\n",
        "\n",
        "data= []\n",
        "for infile in infiles:\n",
        "    w = wave.open(infile, 'rb')\n",
        "    data.append( [w.getparams(), w.readframes(w.getnframes())] )\n",
        "    w.close()\n",
        "    \n",
        "output = wave.open(outfile, 'wb')\n",
        "output.setparams(data[0][0])\n",
        "for i in range(len(data)):\n",
        "    output.writeframes(data[i][1])\n",
        "output.close()\n",
        "files.download(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKQAyGsV9MCk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}